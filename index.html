
<!DOCTYPE html>
<html lang="pt-br">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>LABIT</title>
  <link rel="stylesheet" href="style.css">

</head>
<body>

  <header class="banner">
    <img src="UFPA_Logo.png" alt="Logo" class="logo">
    <img src="LABIT_Logo.jpg" alt="Logo" class="logo">
    <h1>Fichamento <span> LABIT</span></h1>
  </header>

  <section class="breadcrumb">
    ACADÊMICO / ARTIGOS  / LARGE LANGUAGE MODELS (LLM)
  </section>

  <main class="content">
    <h2>
      Análise do artigo:  "A SURVEY ON SPEECH LARGE LANGUAGE MODELS"</h2>
    <div class="meta">
      <span>15 de maio de 2025</span>
      <span>@labit.ufpa</span>
      <span>Deixe um comentário</span>
    </div>

    <p>O artigo "A SURVEY ON SPEECH LARGE LANGUAGE MODELS" foi desenvolvido pelos pesquisadores Jing Peng, Yucheng Wang, YanGui Fang, Yu Xi, Xu Li, Xizhuo Zhang e Kai Yu. E foi publicado na "Electrical Engineering and Systems Science" da Cornell University em 2024.</p>
    <p>O trabalho apresenta o conceito de "Speech LLMs", que consiste em Modelos de LLM focadas em processos específicos como: Reconhecimento de Fala, Transcrição de áudio para texto e Reconhecimento de emoções através de áudio. O principal objetivo do artigo foi analizar os avanços das LLMs no quesito de processamento de áudio e dados multimídia. Analisando a arquitetura dos sistemas, diversos métodos de integração, modelos diferentes e analizar a performance
    na realização de várias tarefas. O artigo apresenta também estratégias de treinamento para Speech LLMs e propõe possíveis soluções para os desafios encontrados .</p>
    <p>Nesse artigo, os autores utilizaram três estágios de treinamento para as LLMs: Alinhamento Modal, Treinamento de Multitarefa e Alinhamento de Instrução e Preferência.   </p>
    <section class="topico">
      <h3>Alinhamento Modal</h2>
        <p>Nessa etapa as LLMs, na maioria das vezes, utilizam uma grande quantidade de dados para suprir os erros na transcrição de áudio. O artigo aponta a estratégia de utilizar um codificador pré-treinado e alinhar as representações acústicas com uma LLM de texto. Então forçar a correspondência entre a saída de texto e a entrada de áudio por meio de tarefas supervisionadas, sendo as fundamentais: Reconhecimento Automático de Fala (ASR) e criação de Legendas para o Áudio (AAC).</p>
        <p>L<sub>aling</sub>(θ) = − log Pθ(y | a)</p>
        <p>O treinamento do modelo é baseado na função acima, mapeando a entrada de áudio a e transcrevendo-a para uma sáida textual y, essa função reduz drasticamente a "cross-entropy loss", que é uma perda de eficiência logarítimica. Isso faz com que o conhecimento do treinamento seja mantido, além de melhorar a sincronia de entrada e saída.</p>
    </section>
        <section class="topico">
      <h3>Treinamento de Multitarefa</h2>
        <p>Essa etapa tem como objetivo desenvolver as capacidades de multitarefa, um único modelo é treinado em uma ampla gama de tarefas supervisionadas, como transcrição de fala, tradução e compreensão de alto-nível de áudio. Esse treinamento possui como entrada uma tripla (a, p, y): Entrada de áudio a, prompt em texto (descrição da tarefa) p, e saída esperada y. O modelo tem como objetivo adivinhar y com base em a e p.</p>
        <p>L<sub>multi</sub>(θ) = &sum; <sub>t∈T</sub> λt E<sub>(a,p,y)</sub>∼Dt− log Pθ(y | a, p)</p>
        <p>Os autores apontaram que essa implementação é feita, por muitos, convertendo cada tarefa para um formato de receita, instruções. O exemplo usado por eles é da Qwen-Audio, que utiliza tokens especiais ou palavras chave em linguagem natural para que a LLM possa diferenciar as tarefas e executar mais de 30 simultaneamente. Eles perceberam que devido ao treinamento conjunto com ASR poliglotas, o modelo adquire um conhecimento amplo e multi-facetado. No mesmo exemplo, a utilização de tarefas com hierarquia se mostrou muito eficaz, onde o modelo resultante atingui resultados de estado-da-arte em várias benchmarks, sem pré-treino das tarefas passadas.</p>
    </section>    <section class="topico">
      <h3>Alinhamento de Instrução e Preferência</h2>
        <p>Nessa etapa, o modelo é alinhado de acordo com as preferências e instruções do usuário, para que siga comandos em linguagem natural de forma confiável e forneça respostas úteis e dentro do contexto especificado. O modelo é ajustado com Datasets "instruction-response", onde cada exemplo conciste em uma conversa ou prompt X, pareado com respostas de alta qualidade Y. Os autores apontam que esse ajuste é necessário para minimizar a semelhança negativa com log nas respostas.</p>
        <p>L<sub>SFT</sub>(θ) = −E<sub>(X,Y)</sub>>∼D<sub>instr</sub>[&sum;<sup>|Y |</sup><sub>t=1</sub> log Pθ(yt | y<sub>&lt;t</sub>, X)]</p>
        <p></p>
    </section>
    <p>Como conclusão dos estudos, os autores destacaram que apesar dos avanços, desafios como a Dormência da LLM - o problema principal do artigo que conciste nas LLMs responderem negativamente a entradas que não foram apresentadas durante o treinamento - ainda persistem. Porém, os autores acreditam que, por apresentar esses desafios e explorar futuras soluções e estratégias, o artigo provê uma valiosa linha de raciocínio para o avanço das Speech LLMs e suas aplicações multimídia.</p>
    <p>Fazendo uma relação, a pesquisa desenvolvida por Jing Peng et al pode ter um impacto direto no desenvolvimento do BOIA, uma vez que o artigo apresenta diversos métodos diferentes e reelevantes para a implementação das funcionalidades desejadas. O artigo apresentou três modos de entrada e saida para Speech LLMs, sendo eles: Fala para Texto (S2P), Fala e Texto para Texto (ST2T) e Fala e Texto para Fala e Texto (ST2ST). Acredito que o modo de melhor aplicação no BOIA seria o ST2T, que consiste em uma entrada de áudio junto com um prompt ou instrução por texto, resultando em um texto.</p>
    </p>
  </main>

</body>
</html>